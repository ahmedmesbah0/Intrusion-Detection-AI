{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Notebook 1: Data Preprocessing\n",
                "\n",
                "## ðŸŽ¯ Objective\n",
                "\n",
                "This notebook handles the preprocessing of the UNSW-NB15 dataset for our intrusion detection system. We will:\n",
                "\n",
                "1. Load the raw dataset from CSV files\n",
                "2. Perform exploratory data inspection\n",
                "3. Clean and handle missing values\n",
                "4. Normalize numerical features\n",
                "5. Encode categorical features\n",
                "6. Create sequences of network flows for temporal modeling\n",
                "7. Split data into train, validation, and test sets\n",
                "8. Save preprocessed data for subsequent notebooks\n",
                "\n",
                "---\n",
                "\n",
                "## ðŸ“š Background: UNSW-NB15 Dataset\n",
                "\n",
                "The UNSW-NB15 dataset is a modern network intrusion detection dataset that contains:\n",
                "- **49 features** describing network flow characteristics\n",
                "- **Normal traffic** and **9 attack categories**\n",
                "- Real-world network traffic patterns\n",
                "\n",
                "**Attack Categories:**\n",
                "- Fuzzers: Attempts to discover vulnerabilities by sending random data\n",
                "- DoS: Denial of Service attacks\n",
                "- Exploits: Exploitation of known vulnerabilities\n",
                "- Reconnaissance: Scanning and probing\n",
                "- Shellcode: Code injection attacks\n",
                "- Analysis, Backdoor, Generic, Worms\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Import Required Libraries\n",
                "\n",
                "We'll use:\n",
                "- **pandas**: For data manipulation\n",
                "- **numpy**: For numerical operations\n",
                "- **sklearn**: For preprocessing and data splitting\n",
                "- **pickle**: For saving processed data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… Libraries imported successfully!\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import pickle\n",
                "import os\n",
                "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
                "from sklearn.model_selection import train_test_split\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Set random seed for reproducibility\n",
                "np.random.seed(42)\n",
                "\n",
                "print(\"âœ… Libraries imported successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Load the Dataset\n",
                "\n",
                "The UNSW-NB15 dataset typically comes in two files:\n",
                "- Training set\n",
                "- Testing set\n",
                "\n",
                "We'll load both and combine them for our preprocessing pipeline."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ðŸ“‚ Loading UNSW-NB15 dataset...\n",
                        "\n",
                        "âœ… Dataset loaded successfully!\n",
                        "   - Training set: 82332 samples\n",
                        "   - Testing set: 82332 samples\n",
                        "   - Combined dataset: 164664 samples, 45 features\n"
                    ]
                }
            ],
            "source": [
                "# Define data paths\n",
                "TRAIN_PATH = r'/home/mesbah7/Github/Repos/Intrusion-Detection-AI/dataset_kaggle/UNSW_NB15_training-set.csv'\n",
                "TEST_PATH = r'/home/mesbah7/Github/Repos/Intrusion-Detection-AI/dataset_kaggle/UNSW_NB15_training-set.csv'\n",
                "\n",
                "# Load the datasets\n",
                "print(\"ðŸ“‚ Loading UNSW-NB15 dataset...\")\n",
                "train_df = pd.read_csv(TRAIN_PATH)\n",
                "test_df = pd.read_csv(TEST_PATH)\n",
                "\n",
                "# Combine both datasets for unified preprocessing\n",
                "df = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
                "\n",
                "print(f\"\\nâœ… Dataset loaded successfully!\")\n",
                "print(f\"   - Training set: {train_df.shape[0]} samples\")\n",
                "print(f\"   - Testing set: {test_df.shape[0]} samples\")\n",
                "print(f\"   - Combined dataset: {df.shape[0]} samples, {df.shape[1]} features\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Initial Data Inspection\n",
                "\n",
                "Let's examine the structure of our dataset to understand:\n",
                "- Feature names and types\n",
                "- Missing values\n",
                "- Basic statistics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ðŸ“Š First 5 rows of the dataset:\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>id</th>\n",
                            "      <th>dur</th>\n",
                            "      <th>proto</th>\n",
                            "      <th>service</th>\n",
                            "      <th>state</th>\n",
                            "      <th>spkts</th>\n",
                            "      <th>dpkts</th>\n",
                            "      <th>sbytes</th>\n",
                            "      <th>dbytes</th>\n",
                            "      <th>rate</th>\n",
                            "      <th>...</th>\n",
                            "      <th>ct_dst_sport_ltm</th>\n",
                            "      <th>ct_dst_src_ltm</th>\n",
                            "      <th>is_ftp_login</th>\n",
                            "      <th>ct_ftp_cmd</th>\n",
                            "      <th>ct_flw_http_mthd</th>\n",
                            "      <th>ct_src_ltm</th>\n",
                            "      <th>ct_srv_dst</th>\n",
                            "      <th>is_sm_ips_ports</th>\n",
                            "      <th>attack_cat</th>\n",
                            "      <th>label</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>1</td>\n",
                            "      <td>0.000011</td>\n",
                            "      <td>udp</td>\n",
                            "      <td>-</td>\n",
                            "      <td>INT</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>496</td>\n",
                            "      <td>0</td>\n",
                            "      <td>90909.0902</td>\n",
                            "      <td>...</td>\n",
                            "      <td>1</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>Normal</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>2</td>\n",
                            "      <td>0.000008</td>\n",
                            "      <td>udp</td>\n",
                            "      <td>-</td>\n",
                            "      <td>INT</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1762</td>\n",
                            "      <td>0</td>\n",
                            "      <td>125000.0003</td>\n",
                            "      <td>...</td>\n",
                            "      <td>1</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>Normal</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>3</td>\n",
                            "      <td>0.000005</td>\n",
                            "      <td>udp</td>\n",
                            "      <td>-</td>\n",
                            "      <td>INT</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1068</td>\n",
                            "      <td>0</td>\n",
                            "      <td>200000.0051</td>\n",
                            "      <td>...</td>\n",
                            "      <td>1</td>\n",
                            "      <td>3</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>3</td>\n",
                            "      <td>0</td>\n",
                            "      <td>Normal</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>4</td>\n",
                            "      <td>0.000006</td>\n",
                            "      <td>udp</td>\n",
                            "      <td>-</td>\n",
                            "      <td>INT</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>900</td>\n",
                            "      <td>0</td>\n",
                            "      <td>166666.6608</td>\n",
                            "      <td>...</td>\n",
                            "      <td>1</td>\n",
                            "      <td>3</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>2</td>\n",
                            "      <td>3</td>\n",
                            "      <td>0</td>\n",
                            "      <td>Normal</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>5</td>\n",
                            "      <td>0.000010</td>\n",
                            "      <td>udp</td>\n",
                            "      <td>-</td>\n",
                            "      <td>INT</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>2126</td>\n",
                            "      <td>0</td>\n",
                            "      <td>100000.0025</td>\n",
                            "      <td>...</td>\n",
                            "      <td>1</td>\n",
                            "      <td>3</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>2</td>\n",
                            "      <td>3</td>\n",
                            "      <td>0</td>\n",
                            "      <td>Normal</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>5 rows Ã— 45 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   id       dur proto service state  spkts  dpkts  sbytes  dbytes  \\\n",
                            "0   1  0.000011   udp       -   INT      2      0     496       0   \n",
                            "1   2  0.000008   udp       -   INT      2      0    1762       0   \n",
                            "2   3  0.000005   udp       -   INT      2      0    1068       0   \n",
                            "3   4  0.000006   udp       -   INT      2      0     900       0   \n",
                            "4   5  0.000010   udp       -   INT      2      0    2126       0   \n",
                            "\n",
                            "          rate  ...  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  \\\n",
                            "0   90909.0902  ...                 1               2             0   \n",
                            "1  125000.0003  ...                 1               2             0   \n",
                            "2  200000.0051  ...                 1               3             0   \n",
                            "3  166666.6608  ...                 1               3             0   \n",
                            "4  100000.0025  ...                 1               3             0   \n",
                            "\n",
                            "   ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  \\\n",
                            "0           0                 0           1           2                0   \n",
                            "1           0                 0           1           2                0   \n",
                            "2           0                 0           1           3                0   \n",
                            "3           0                 0           2           3                0   \n",
                            "4           0                 0           2           3                0   \n",
                            "\n",
                            "   attack_cat  label  \n",
                            "0      Normal      0  \n",
                            "1      Normal      0  \n",
                            "2      Normal      0  \n",
                            "3      Normal      0  \n",
                            "4      Normal      0  \n",
                            "\n",
                            "[5 rows x 45 columns]"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Display first few rows\n",
                "print(\"ðŸ“Š First 5 rows of the dataset:\")\n",
                "df.head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Index(['id', 'dur', 'proto', 'service', 'state', 'spkts', 'dpkts', 'sbytes',\n",
                            "       'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss', 'dloss',\n",
                            "       'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb', 'dwin',\n",
                            "       'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'trans_depth',\n",
                            "       'response_body_len', 'ct_srv_src', 'ct_state_ttl', 'ct_dst_ltm',\n",
                            "       'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm',\n",
                            "       'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'ct_src_ltm',\n",
                            "       'ct_srv_dst', 'is_sm_ips_ports', 'attack_cat', 'label'],\n",
                            "      dtype='object')"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.columns"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>id</th>\n",
                            "      <th>dur</th>\n",
                            "      <th>proto</th>\n",
                            "      <th>service</th>\n",
                            "      <th>state</th>\n",
                            "      <th>spkts</th>\n",
                            "      <th>dpkts</th>\n",
                            "      <th>sbytes</th>\n",
                            "      <th>dbytes</th>\n",
                            "      <th>rate</th>\n",
                            "      <th>...</th>\n",
                            "      <th>ct_dst_sport_ltm</th>\n",
                            "      <th>ct_dst_src_ltm</th>\n",
                            "      <th>is_ftp_login</th>\n",
                            "      <th>ct_ftp_cmd</th>\n",
                            "      <th>ct_flw_http_mthd</th>\n",
                            "      <th>ct_src_ltm</th>\n",
                            "      <th>ct_srv_dst</th>\n",
                            "      <th>is_sm_ips_ports</th>\n",
                            "      <th>attack_cat</th>\n",
                            "      <th>label</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>1</td>\n",
                            "      <td>0.000011</td>\n",
                            "      <td>udp</td>\n",
                            "      <td>-</td>\n",
                            "      <td>INT</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>496</td>\n",
                            "      <td>0</td>\n",
                            "      <td>90909.09020</td>\n",
                            "      <td>...</td>\n",
                            "      <td>1</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>Normal</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>2</td>\n",
                            "      <td>0.000008</td>\n",
                            "      <td>udp</td>\n",
                            "      <td>-</td>\n",
                            "      <td>INT</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1762</td>\n",
                            "      <td>0</td>\n",
                            "      <td>125000.00030</td>\n",
                            "      <td>...</td>\n",
                            "      <td>1</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>Normal</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>3</td>\n",
                            "      <td>0.000005</td>\n",
                            "      <td>udp</td>\n",
                            "      <td>-</td>\n",
                            "      <td>INT</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1068</td>\n",
                            "      <td>0</td>\n",
                            "      <td>200000.00510</td>\n",
                            "      <td>...</td>\n",
                            "      <td>1</td>\n",
                            "      <td>3</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>3</td>\n",
                            "      <td>0</td>\n",
                            "      <td>Normal</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>4</td>\n",
                            "      <td>0.000006</td>\n",
                            "      <td>udp</td>\n",
                            "      <td>-</td>\n",
                            "      <td>INT</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>900</td>\n",
                            "      <td>0</td>\n",
                            "      <td>166666.66080</td>\n",
                            "      <td>...</td>\n",
                            "      <td>1</td>\n",
                            "      <td>3</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>2</td>\n",
                            "      <td>3</td>\n",
                            "      <td>0</td>\n",
                            "      <td>Normal</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>5</td>\n",
                            "      <td>0.000010</td>\n",
                            "      <td>udp</td>\n",
                            "      <td>-</td>\n",
                            "      <td>INT</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>2126</td>\n",
                            "      <td>0</td>\n",
                            "      <td>100000.00250</td>\n",
                            "      <td>...</td>\n",
                            "      <td>1</td>\n",
                            "      <td>3</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>2</td>\n",
                            "      <td>3</td>\n",
                            "      <td>0</td>\n",
                            "      <td>Normal</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>6</td>\n",
                            "      <td>0.000003</td>\n",
                            "      <td>udp</td>\n",
                            "      <td>-</td>\n",
                            "      <td>INT</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>784</td>\n",
                            "      <td>0</td>\n",
                            "      <td>333333.32150</td>\n",
                            "      <td>...</td>\n",
                            "      <td>1</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>2</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>Normal</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6</th>\n",
                            "      <td>7</td>\n",
                            "      <td>0.000006</td>\n",
                            "      <td>udp</td>\n",
                            "      <td>-</td>\n",
                            "      <td>INT</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1960</td>\n",
                            "      <td>0</td>\n",
                            "      <td>166666.66080</td>\n",
                            "      <td>...</td>\n",
                            "      <td>1</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>2</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>Normal</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>7</th>\n",
                            "      <td>8</td>\n",
                            "      <td>0.000028</td>\n",
                            "      <td>udp</td>\n",
                            "      <td>-</td>\n",
                            "      <td>INT</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1384</td>\n",
                            "      <td>0</td>\n",
                            "      <td>35714.28522</td>\n",
                            "      <td>...</td>\n",
                            "      <td>1</td>\n",
                            "      <td>3</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>3</td>\n",
                            "      <td>0</td>\n",
                            "      <td>Normal</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>8</th>\n",
                            "      <td>9</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>arp</td>\n",
                            "      <td>-</td>\n",
                            "      <td>INT</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>46</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0.00000</td>\n",
                            "      <td>...</td>\n",
                            "      <td>2</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>2</td>\n",
                            "      <td>2</td>\n",
                            "      <td>1</td>\n",
                            "      <td>Normal</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>9</th>\n",
                            "      <td>10</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>arp</td>\n",
                            "      <td>-</td>\n",
                            "      <td>INT</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>46</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0.00000</td>\n",
                            "      <td>...</td>\n",
                            "      <td>2</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>2</td>\n",
                            "      <td>2</td>\n",
                            "      <td>1</td>\n",
                            "      <td>Normal</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>10 rows Ã— 45 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   id       dur proto service state  spkts  dpkts  sbytes  dbytes  \\\n",
                            "0   1  0.000011   udp       -   INT      2      0     496       0   \n",
                            "1   2  0.000008   udp       -   INT      2      0    1762       0   \n",
                            "2   3  0.000005   udp       -   INT      2      0    1068       0   \n",
                            "3   4  0.000006   udp       -   INT      2      0     900       0   \n",
                            "4   5  0.000010   udp       -   INT      2      0    2126       0   \n",
                            "5   6  0.000003   udp       -   INT      2      0     784       0   \n",
                            "6   7  0.000006   udp       -   INT      2      0    1960       0   \n",
                            "7   8  0.000028   udp       -   INT      2      0    1384       0   \n",
                            "8   9  0.000000   arp       -   INT      1      0      46       0   \n",
                            "9  10  0.000000   arp       -   INT      1      0      46       0   \n",
                            "\n",
                            "           rate  ...  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  \\\n",
                            "0   90909.09020  ...                 1               2             0   \n",
                            "1  125000.00030  ...                 1               2             0   \n",
                            "2  200000.00510  ...                 1               3             0   \n",
                            "3  166666.66080  ...                 1               3             0   \n",
                            "4  100000.00250  ...                 1               3             0   \n",
                            "5  333333.32150  ...                 1               2             0   \n",
                            "6  166666.66080  ...                 1               2             0   \n",
                            "7   35714.28522  ...                 1               3             0   \n",
                            "8       0.00000  ...                 2               2             0   \n",
                            "9       0.00000  ...                 2               2             0   \n",
                            "\n",
                            "   ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  \\\n",
                            "0           0                 0           1           2                0   \n",
                            "1           0                 0           1           2                0   \n",
                            "2           0                 0           1           3                0   \n",
                            "3           0                 0           2           3                0   \n",
                            "4           0                 0           2           3                0   \n",
                            "5           0                 0           2           2                0   \n",
                            "6           0                 0           2           2                0   \n",
                            "7           0                 0           1           3                0   \n",
                            "8           0                 0           2           2                1   \n",
                            "9           0                 0           2           2                1   \n",
                            "\n",
                            "   attack_cat  label  \n",
                            "0      Normal      0  \n",
                            "1      Normal      0  \n",
                            "2      Normal      0  \n",
                            "3      Normal      0  \n",
                            "4      Normal      0  \n",
                            "5      Normal      0  \n",
                            "6      Normal      0  \n",
                            "7      Normal      0  \n",
                            "8      Normal      0  \n",
                            "9      Normal      0  \n",
                            "\n",
                            "[10 rows x 45 columns]"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.head(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "service\n",
                            "-           94306\n",
                            "dns         42734\n",
                            "http        16574\n",
                            "smtp         3702\n",
                            "ftp          3104\n",
                            "ftp-data     2792\n",
                            "pop3          846\n",
                            "ssh           408\n",
                            "ssl            60\n",
                            "snmp           58\n",
                            "dhcp           52\n",
                            "radius         18\n",
                            "irc            10\n",
                            "Name: count, dtype: int64"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df['service'].value_counts()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "service\n",
                            "dns         137040\n",
                            "http         16574\n",
                            "smtp          3702\n",
                            "ftp           3104\n",
                            "ftp-data      2792\n",
                            "pop3           846\n",
                            "ssh            408\n",
                            "ssl             60\n",
                            "snmp            58\n",
                            "dhcp            52\n",
                            "radius          18\n",
                            "irc             10\n",
                            "Name: count, dtype: int64"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "most_frequent = df[df['service'] != '-']['service'].mode()[0]\n",
                "df['service'] = df['service'].replace('-', most_frequent)\n",
                "# In your case, this would replace all '-' with 'dns'\n",
                "df['service'].value_counts()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "ðŸ” Missing values per column:\n",
                        "No missing values found!\n"
                    ]
                }
            ],
            "source": [
                "# Check for missing values\n",
                "print(\"\\nðŸ” Missing values per column:\")\n",
                "missing = df.isnull().sum()\n",
                "missing = missing[missing > 0].sort_values(ascending=False)\n",
                "if len(missing) > 0:\n",
                "    print(missing)\n",
                "else:\n",
                "    print(\"No missing values found!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "ðŸ“Š Class Distribution:\n",
                        "label\n",
                        "1    90664\n",
                        "0    74000\n",
                        "Name: count, dtype: int64\n",
                        "\n",
                        "Normal traffic: 74000 samples\n",
                        "Attack traffic: 90664 samples\n",
                        "Attack ratio: 55.06%\n",
                        "\n",
                        "ðŸŽ¯ Attack Categories:\n",
                        "attack_cat\n",
                        "Normal            74000\n",
                        "Generic           37742\n",
                        "Exploits          22264\n",
                        "Fuzzers           12124\n",
                        "DoS                8178\n",
                        "Reconnaissance     6992\n",
                        "Analysis           1354\n",
                        "Backdoor           1166\n",
                        "Shellcode           756\n",
                        "Worms                88\n",
                        "Name: count, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "# Check class distribution\n",
                "print(\"\\nðŸ“Š Class Distribution:\")\n",
                "if 'label' in df.columns:\n",
                "    print(df['label'].value_counts())\n",
                "    print(f\"\\nNormal traffic: {(df['label'] == 0).sum()} samples\")\n",
                "    print(f\"Attack traffic: {(df['label'] == 1).sum()} samples\")\n",
                "    print(f\"Attack ratio: {(df['label'] == 1).sum() / len(df) * 100:.2f}%\")\n",
                "\n",
                "if 'attack_cat' in df.columns:\n",
                "    print(\"\\nðŸŽ¯ Attack Categories:\")\n",
                "    print(df['attack_cat'].value_counts())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 4: Feature Selection and Cleaning\n",
                "\n",
                "We'll:\n",
                "1. Identify and separate feature types (numerical vs categorical)\n",
                "2. Remove irrelevant features (IDs, timestamps that don't add value)\n",
                "3. Handle missing values\n",
                "4. Store labels for later use"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… Selected 42 features for modeling\n",
                        "\n",
                        "Feature columns: ['dur', 'proto', 'service', 'state', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss', 'dloss', 'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb', 'dwin', 'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'trans_depth', 'response_body_len', 'ct_srv_src', 'ct_state_ttl', 'ct_dst_ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'ct_src_ltm', 'ct_srv_dst', 'is_sm_ips_ports']\n"
                    ]
                }
            ],
            "source": [
                "# Store labels separately\n",
                "labels = df['label'].values if 'label' in df.columns else None\n",
                "attack_categories = df['attack_cat'].values if 'attack_cat' in df.columns else None\n",
                "\n",
                "# Features to drop (non-predictive or identifier columns)\n",
                "# Adjust these based on your specific dataset columns\n",
                "columns_to_drop = ['id', 'label', 'attack_cat']\n",
                "columns_to_drop = [col for col in columns_to_drop if col in df.columns]\n",
                "\n",
                "# Create feature dataframe\n",
                "features_df = df.drop(columns=columns_to_drop, errors='ignore')\n",
                "\n",
                "print(f\"âœ… Selected {features_df.shape[1]} features for modeling\")\n",
                "print(f\"\\nFeature columns: {list(features_df.columns)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ðŸ”¢ Numerical features: 39\n",
                        "ðŸ“ Categorical features: 3\n",
                        "\n",
                        "Categorical columns: ['proto', 'service', 'state']\n"
                    ]
                }
            ],
            "source": [
                "# Identify categorical and numerical columns\n",
                "categorical_cols = features_df.select_dtypes(include=['object']).columns.tolist()\n",
                "numerical_cols = features_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
                "\n",
                "print(f\"ðŸ”¢ Numerical features: {len(numerical_cols)}\")\n",
                "print(f\"ðŸ“ Categorical features: {len(categorical_cols)}\")\n",
                "print(f\"\\nCategorical columns: {categorical_cols}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 5: Handle Missing Values\n",
                "\n",
                "For missing values:\n",
                "- **Numerical features**: Fill with median\n",
                "- **Categorical features**: Fill with mode or 'unknown'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "âœ… Missing values handled!\n"
                    ]
                }
            ],
            "source": [
                "# Handle missing values in numerical columns\n",
                "for col in numerical_cols:\n",
                "    if features_df[col].isnull().sum() > 0:\n",
                "        median_value = features_df[col].median()\n",
                "        features_df[col].fillna(median_value, inplace=True)\n",
                "        print(f\"Filled {col} with median: {median_value}\")\n",
                "\n",
                "# Handle missing values in categorical columns\n",
                "for col in categorical_cols:\n",
                "    if features_df[col].isnull().sum() > 0:\n",
                "        features_df[col].fillna('unknown', inplace=True)\n",
                "        print(f\"Filled {col} with 'unknown'\")\n",
                "\n",
                "print(\"\\nâœ… Missing values handled!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 6: Encode Categorical Features\n",
                "\n",
                "We need to convert categorical variables (like protocol type, service, state) into numerical values using Label Encoding."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Encoded proto: 131 unique values\n",
                        "Encoded service: 12 unique values\n",
                        "Encoded state: 7 unique values\n",
                        "\n",
                        "âœ… Categorical features encoded!\n"
                    ]
                }
            ],
            "source": [
                "# Initialize label encoders dictionary to save for later use\n",
                "label_encoders = {}\n",
                "\n",
                "# Encode categorical columns\n",
                "for col in categorical_cols:\n",
                "    le = LabelEncoder()\n",
                "    features_df[col] = le.fit_transform(features_df[col].astype(str))\n",
                "    label_encoders[col] = le\n",
                "    print(f\"Encoded {col}: {len(le.classes_)} unique values\")\n",
                "\n",
                "print(\"\\nâœ… Categorical features encoded!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 7: Normalize Numerical Features\n",
                "\n",
                "Neural networks perform better with normalized data. We'll use MinMaxScaler to scale all features to the range [0, 1]."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… Features normalized to range [0, 1]\n",
                        "\n",
                        "Scaled features shape: (164664, 42)\n",
                        "\n",
                        "Sample statistics after scaling:\n",
                        "                dur          proto        service          state  \\\n",
                        "count  1.646640e+05  164664.000000  164664.000000  164664.000000   \n",
                        "mean   1.677927e-02       0.841141       0.142466       0.562459   \n",
                        "std    7.850718e-02       0.143363       0.133791       0.111728   \n",
                        "min    0.000000e+00       0.000000       0.000000       0.000000   \n",
                        "25%    1.333334e-07       0.853846       0.090909       0.500000   \n",
                        "50%    2.356334e-04       0.853846       0.090909       0.500000   \n",
                        "75%    1.198934e-02       0.900000       0.090909       0.666667   \n",
                        "max    1.000000e+00       1.000000       1.000000       1.000000   \n",
                        "\n",
                        "               spkts          dpkts         sbytes         dbytes  \\\n",
                        "count  164664.000000  164664.000000  164664.000000  164664.000000   \n",
                        "mean        0.001660       0.001592       0.000555       0.000903   \n",
                        "std         0.012580       0.010490       0.011956       0.010334   \n",
                        "min         0.000000       0.000000       0.000000       0.000000   \n",
                        "25%         0.000094       0.000000       0.000006       0.000000   \n",
                        "50%         0.000470       0.000182       0.000036       0.000012   \n",
                        "75%         0.001033       0.000908       0.000087       0.000065   \n",
                        "max         1.000000       1.000000       1.000000       1.000000   \n",
                        "\n",
                        "                rate           sttl  ...     ct_dst_ltm  ct_src_dport_ltm  \\\n",
                        "count  164664.000000  164664.000000  ...  164664.000000     164664.000000   \n",
                        "mean        0.082411       0.709677  ...       0.081809          0.067740   \n",
                        "std         0.148620       0.398090  ...       0.145139          0.144647   \n",
                        "min         0.000000       0.000000  ...       0.000000          0.000000   \n",
                        "25%         0.000029       0.243137  ...       0.000000          0.000000   \n",
                        "50%         0.002650       0.996078  ...       0.017241          0.000000   \n",
                        "75%         0.111111       0.996078  ...       0.086207          0.051724   \n",
                        "max         1.000000       1.000000  ...       1.000000          1.000000   \n",
                        "\n",
                        "       ct_dst_sport_ltm  ct_dst_src_ltm   is_ftp_login     ct_ftp_cmd  \\\n",
                        "count     164664.000000   164664.000000  164664.000000  164664.000000   \n",
                        "mean           0.071973        0.104135       0.004142       0.004190   \n",
                        "std            0.159875        0.184115       0.045585       0.046242   \n",
                        "min            0.000000        0.000000       0.000000       0.000000   \n",
                        "25%            0.000000        0.000000       0.000000       0.000000   \n",
                        "50%            0.000000        0.032258       0.000000       0.000000   \n",
                        "75%            0.054054        0.080645       0.000000       0.000000   \n",
                        "max            1.000000        1.000000       1.000000       1.000000   \n",
                        "\n",
                        "       ct_flw_http_mthd     ct_src_ltm     ct_srv_dst  is_sm_ips_ports  \n",
                        "count     164664.000000  164664.000000  164664.000000    164664.000000  \n",
                        "mean           0.008109       0.092684       0.133840         0.011126  \n",
                        "std            0.039918       0.144812       0.182318         0.104890  \n",
                        "min            0.000000       0.000000       0.000000         0.000000  \n",
                        "25%            0.000000       0.000000       0.016393         0.000000  \n",
                        "50%            0.000000       0.033898       0.065574         0.000000  \n",
                        "75%            0.000000       0.101695       0.163934         0.000000  \n",
                        "max            1.000000       1.000000       1.000000         1.000000  \n",
                        "\n",
                        "[8 rows x 42 columns]\n"
                    ]
                }
            ],
            "source": [
                "# Create and fit the scaler\n",
                "scaler = MinMaxScaler()\n",
                "features_scaled = scaler.fit_transform(features_df)\n",
                "\n",
                "# Convert back to DataFrame for easier handling\n",
                "features_scaled_df = pd.DataFrame(features_scaled, columns=features_df.columns)\n",
                "\n",
                "print(f\"âœ… Features normalized to range [0, 1]\")\n",
                "print(f\"\\nScaled features shape: {features_scaled_df.shape}\")\n",
                "print(f\"\\nSample statistics after scaling:\")\n",
                "print(features_scaled_df.describe())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 8: Create Sequences for Temporal Modeling\n",
                "\n",
                "For our CNN+LSTM autoencoder, we need to create sequences of network flows. \n",
                "\n",
                "**Why sequences?**\n",
                "- Network attacks often span multiple packets/flows\n",
                "- Temporal patterns help identify anomalies\n",
                "- LSTM can learn time dependencies\n",
                "\n",
                "We'll use a sliding window approach to create fixed-length sequences."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Creating sequences with length=10, stride=5...\n",
                        "\n",
                        "âœ… Sequences created!\n",
                        "   - Number of sequences: 32931\n",
                        "   - Sequence shape: (10, 42)\n",
                        "   - Normal sequences: 14791\n",
                        "   - Attack sequences: 18140\n"
                    ]
                }
            ],
            "source": [
                "def create_sequences(data, labels, sequence_length=10, stride=5):\n",
                "    \"\"\"\n",
                "    Create sequences from the dataset using a sliding window.\n",
                "    \n",
                "    Parameters:\n",
                "    -----------\n",
                "    data : array-like\n",
                "        Feature data (samples x features)\n",
                "    labels : array-like\n",
                "        Binary labels (0=normal, 1=attack)\n",
                "    sequence_length : int\n",
                "        Length of each sequence (number of flows)\n",
                "    stride : int\n",
                "        Step size for sliding window\n",
                "    \n",
                "    Returns:\n",
                "    --------\n",
                "    sequences : ndarray\n",
                "        Sequences of shape (num_sequences, sequence_length, num_features)\n",
                "    sequence_labels : ndarray\n",
                "        Labels for each sequence (1 if any flow in sequence is attack)\n",
                "    \"\"\"\n",
                "    sequences = []\n",
                "    sequence_labels = []\n",
                "    \n",
                "    # Sliding window to create sequences\n",
                "    for i in range(0, len(data) - sequence_length + 1, stride):\n",
                "        # Extract sequence\n",
                "        seq = data[i:i + sequence_length]\n",
                "        \n",
                "        # Label is 1 if any flow in the sequence is an attack\n",
                "        label = labels[i:i + sequence_length]\n",
                "        seq_label = 1 if np.any(label == 1) else 0\n",
                "        \n",
                "        sequences.append(seq)\n",
                "        sequence_labels.append(seq_label)\n",
                "    \n",
                "    return np.array(sequences), np.array(sequence_labels)\n",
                "\n",
                "# Set sequence parameters\n",
                "SEQUENCE_LENGTH = 10  # Each sequence contains 10 network flows\n",
                "STRIDE = 5            # Move 5 flows forward for next sequence\n",
                "\n",
                "print(f\"Creating sequences with length={SEQUENCE_LENGTH}, stride={STRIDE}...\")\n",
                "\n",
                "# Create sequences\n",
                "X_sequences, y_sequences = create_sequences(\n",
                "    features_scaled_df.values, \n",
                "    labels, \n",
                "    sequence_length=SEQUENCE_LENGTH,\n",
                "    stride=STRIDE\n",
                ")\n",
                "\n",
                "print(f\"\\nâœ… Sequences created!\")\n",
                "print(f\"   - Number of sequences: {X_sequences.shape[0]}\")\n",
                "print(f\"   - Sequence shape: {X_sequences.shape[1:]}\")\n",
                "print(f\"   - Normal sequences: {np.sum(y_sequences == 0)}\")\n",
                "print(f\"   - Attack sequences: {np.sum(y_sequences == 1)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 9: Split Data into Train, Validation, and Test Sets\n",
                "\n",
                "We'll split the data:\n",
                "- **70%** Training set (for model training)\n",
                "- **15%** Validation set (for hyperparameter tuning)\n",
                "- **15%** Test set (for final evaluation)\n",
                "\n",
                "**Important**: For autoencoder training, we'll primarily use normal traffic in the training set!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… Data split completed!\n",
                        "\n",
                        "Training set:\n",
                        "   - Shape: (23051, 10, 42)\n",
                        "   - Normal: 10353, Attack: 12698\n",
                        "\n",
                        "Validation set:\n",
                        "   - Shape: (4940, 10, 42)\n",
                        "   - Normal: 2219, Attack: 2721\n",
                        "\n",
                        "Test set:\n",
                        "   - Shape: (4940, 10, 42)\n",
                        "   - Normal: 2219, Attack: 2721\n"
                    ]
                }
            ],
            "source": [
                "# First split: 70% train, 30% temp (for validation and test)\n",
                "X_train, X_temp, y_train, y_temp = train_test_split(\n",
                "    X_sequences, y_sequences, \n",
                "    test_size=0.3, \n",
                "    random_state=42,\n",
                "    stratify=y_sequences  # Maintain class distribution\n",
                ")\n",
                "\n",
                "# Second split: Split temp into 50% validation, 50% test (15% each of total)\n",
                "X_val, X_test, y_val, y_test = train_test_split(\n",
                "    X_temp, y_temp, \n",
                "    test_size=0.5, \n",
                "    random_state=42,\n",
                "    stratify=y_temp\n",
                ")\n",
                "\n",
                "print(\"âœ… Data split completed!\")\n",
                "print(f\"\\nTraining set:\")\n",
                "print(f\"   - Shape: {X_train.shape}\")\n",
                "print(f\"   - Normal: {np.sum(y_train == 0)}, Attack: {np.sum(y_train == 1)}\")\n",
                "\n",
                "print(f\"\\nValidation set:\")\n",
                "print(f\"   - Shape: {X_val.shape}\")\n",
                "print(f\"   - Normal: {np.sum(y_val == 0)}, Attack: {np.sum(y_val == 1)}\")\n",
                "\n",
                "print(f\"\\nTest set:\")\n",
                "print(f\"   - Shape: {X_test.shape}\")\n",
                "print(f\"   - Normal: {np.sum(y_test == 0)}, Attack: {np.sum(y_test == 1)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 10: Extract Normal Traffic for Autoencoder Training\n",
                "\n",
                "Autoencoders learn to reconstruct normal patterns. We train only on normal traffic, then use reconstruction error to detect anomalies (attacks)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… Extracted normal traffic for autoencoder training\n",
                        "   - Normal training sequences: 10353\n",
                        "   - This represents 44.9% of training data\n"
                    ]
                }
            ],
            "source": [
                "# Extract only normal traffic for training the autoencoder\n",
                "X_train_normal = X_train[y_train == 0]\n",
                "\n",
                "print(f\"âœ… Extracted normal traffic for autoencoder training\")\n",
                "print(f\"   - Normal training sequences: {X_train_normal.shape[0]}\")\n",
                "print(f\"   - This represents {X_train_normal.shape[0] / X_train.shape[0] * 100:.1f}% of training data\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 11: Save Preprocessed Data\n",
                "\n",
                "We'll save all preprocessed data for use in subsequent notebooks."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… All preprocessed data saved successfully!\n",
                        "\n",
                        "ðŸ“ Saved files:\n",
                        "   - X_train.npy, X_train_normal.npy, X_val.npy, X_test.npy\n",
                        "   - y_train.npy, y_val.npy, y_test.npy\n",
                        "   - scaler.pkl, label_encoders.pkl, feature_names.pkl\n"
                    ]
                }
            ],
            "source": [
                "# Create output directory\n",
                "os.makedirs('preprocessed_data', exist_ok=True)\n",
                "\n",
                "# Save data as numpy arrays\n",
                "np.save('preprocessed_data/X_train.npy', X_train)\n",
                "np.save('preprocessed_data/X_train_normal.npy', X_train_normal)\n",
                "np.save('preprocessed_data/X_val.npy', X_val)\n",
                "np.save('preprocessed_data/X_test.npy', X_test)\n",
                "np.save('preprocessed_data/y_train.npy', y_train)\n",
                "np.save('preprocessed_data/y_val.npy', y_val)\n",
                "np.save('preprocessed_data/y_test.npy', y_test)\n",
                "\n",
                "# Save preprocessing objects\n",
                "with open('preprocessed_data/scaler.pkl', 'wb') as f:\n",
                "    pickle.dump(scaler, f)\n",
                "\n",
                "with open('preprocessed_data/label_encoders.pkl', 'wb') as f:\n",
                "    pickle.dump(label_encoders, f)\n",
                "\n",
                "# Save feature names\n",
                "with open('preprocessed_data/feature_names.pkl', 'wb') as f:\n",
                "    pickle.dump(list(features_df.columns), f)\n",
                "\n",
                "print(\"âœ… All preprocessed data saved successfully!\")\n",
                "print(\"\\nðŸ“ Saved files:\")\n",
                "print(\"   - X_train.npy, X_train_normal.npy, X_val.npy, X_test.npy\")\n",
                "print(\"   - y_train.npy, y_val.npy, y_test.npy\")\n",
                "print(\"   - scaler.pkl, label_encoders.pkl, feature_names.pkl\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ“Š Summary\n",
                "\n",
                "In this notebook, we successfully:\n",
                "\n",
                "1. âœ… Loaded the UNSW-NB15 dataset\n",
                "2. âœ… Inspected and cleaned the data\n",
                "3. âœ… Handled missing values\n",
                "4. âœ… Encoded categorical features\n",
                "5. âœ… Normalized all features to [0, 1] range\n",
                "6. âœ… Created sequences for temporal modeling\n",
                "7. âœ… Split data into train/validation/test sets\n",
                "8. âœ… Extracted normal traffic for autoencoder training\n",
                "9. âœ… Saved all preprocessed data\n",
                "\n",
                "---\n",
                "\n",
                "## ðŸŽ¯ Next Steps\n",
                "\n",
                "Proceed to **Notebook 2: Visualization** to:\n",
                "- Explore feature distributions\n",
                "- Visualize attack patterns\n",
                "- Understand correlations\n",
                "- Gain insights into the dataset\n",
                "\n",
                "---\n",
                "\n",
                "**Note**: Make sure the `preprocessed_data/` directory contains all saved files before proceeding to the next notebook!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
